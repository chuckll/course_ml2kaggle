{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max target value is 50.0\n",
      "The min target value is 5.0\n",
      "The average target value is 22.532806324110677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 33,test_size = 0.25)\n",
    "\n",
    "#分析回归目标值的差异\n",
    "print(\"The max target value is\",np.max(y))\n",
    "print(\"The min target value is\",np.min(y))\n",
    "print(\"The average target value is\",np.mean(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[33.8 20.3 10.2 22.  21.2 24.2 29.  22.7 21.8 34.9 25.2 20.9 19.4 20.\n 14.  30.1 33.1 20.6 22.6 33.4 20.1 10.5 15.6 16.8 22.6 34.6 19.8 17.8\n 22.  17.4 15.4 16.7 22.6 15.1 21.4 15.3  7.4 13.9 17.6 25.  46.7 17.1\n 23.1 18.7 21.9 18.9 26.7 22.3 25.  14.6 42.8 17.3 22.2 36.5 22.8 19.9\n 36.2 50.  25.  22.2 17.5 23.9 19.6 24.7 28.4  8.7 21.7 20.  19.9 24.5\n 15.   7.  15.2 20.4  8.5 17.1 30.1 15.  19.4 23.2 17.  18.9 50.  25.\n 46.   7.2 17.8 35.1 24.3  5.  16.6 21.8 28.5 22.  20.3 21.7 26.4 30.7\n 50.  17.2 26.6 21.  23.4 19.5 20.7 23.3 48.8 15.6 19.6 17.4 21.7 14.6\n 37.9  9.7 17.8 12.1 20.1 29.9 26.4 18.8 32.5 15.7 13.4 21.7 23.6 11.9\n 13.8 22.2 13.  33.2 50.  22.3 22.4 23.8 29.1 20.8 23.7 19.8 13.9 28.4\n 45.4 23.7 50.  18.  17.1 18.9 10.4 24.7 23.9 23.  20.2  8.5 14.2 20.3\n 18.5 12.  19.3 20.6 16.1 12.3 23.1 22.7 20.3 16.7 27.9 21.4  8.1 37.6\n 15.6 29.6 22.9 24.8 24.4 50.  28.7 50.  16.5 18.2 50.  16.2 14.1 21.2\n 18.4 25.  50.  21.2 20.4 15.2 22.  19.8 22.1 23.9 24.6 23.9 21.7 44.8\n  7.2 18.5 20.1 23.3 19.2 29.1 31.  22.9 27.5 39.8 22.  22.8 22.9 14.3\n 14.5 22.4 19.3 32.  20.1 18.3 24.5 18.4 23.1 22.6 20.2 17.8 31.6 43.5\n 36.4 11.3 20.5 23.2 29.8 20.6 24.3 18.1 19.1 21.4 31.5 19.2 14.3 24.8\n 21.1 18.2 48.3 19.4 21.2 10.9 27.5 34.7 14.4 22.8 17.8 50.  24.4 12.8\n 30.8 28.2 25.  33.1 27.5 12.7 43.1 13.4 21.5 33.4 23.8 21.  26.6 18.5\n 23.  24.1 20.5 32.2 14.4 11.8 19.5 23.7 13.2 29.  18.2 18.6 23.  42.3\n 17.2 16.2 20.  30.3 20.9 20.4 24.8 18.7 16.8 22.5 18.8 23.7 23.8 19.6\n 20.4 16.1 44.  19.3 17.4 10.2 11.7 37.2 11.  23.6 22.8 15.  34.9 17.9\n 24.4 24.5  6.3 29.4 10.4 38.7 20.  19.4 37.  50.  18.7 48.5 35.4 23.4\n  7.  50.  20.7 35.4  9.6 25.1 16.1 27.  16.6 13.3 25.  24.  19.6 29.6\n 21.7 19.1 22.  13.3 27.1 22.9 33.2 13.5 14.5  8.3 41.7 31.2 23.9 23.1\n 24.3 18.3 20.8 28.  19.5 21.5 13.1 12.5 31.7 13.1 23.1 14.5 22.2 13.1\n 37.3 22.  10.2  5.  19.3 16.  18.6 50.  31.6 24.1 15.6 19.4 23.3 23.2\n 13.6].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3a93d42140cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mss_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mss_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \"\"\"\n\u001b[0;32m    611\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m--> 612\u001b[1;33m                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[33.8 20.3 10.2 22.  21.2 24.2 29.  22.7 21.8 34.9 25.2 20.9 19.4 20.\n 14.  30.1 33.1 20.6 22.6 33.4 20.1 10.5 15.6 16.8 22.6 34.6 19.8 17.8\n 22.  17.4 15.4 16.7 22.6 15.1 21.4 15.3  7.4 13.9 17.6 25.  46.7 17.1\n 23.1 18.7 21.9 18.9 26.7 22.3 25.  14.6 42.8 17.3 22.2 36.5 22.8 19.9\n 36.2 50.  25.  22.2 17.5 23.9 19.6 24.7 28.4  8.7 21.7 20.  19.9 24.5\n 15.   7.  15.2 20.4  8.5 17.1 30.1 15.  19.4 23.2 17.  18.9 50.  25.\n 46.   7.2 17.8 35.1 24.3  5.  16.6 21.8 28.5 22.  20.3 21.7 26.4 30.7\n 50.  17.2 26.6 21.  23.4 19.5 20.7 23.3 48.8 15.6 19.6 17.4 21.7 14.6\n 37.9  9.7 17.8 12.1 20.1 29.9 26.4 18.8 32.5 15.7 13.4 21.7 23.6 11.9\n 13.8 22.2 13.  33.2 50.  22.3 22.4 23.8 29.1 20.8 23.7 19.8 13.9 28.4\n 45.4 23.7 50.  18.  17.1 18.9 10.4 24.7 23.9 23.  20.2  8.5 14.2 20.3\n 18.5 12.  19.3 20.6 16.1 12.3 23.1 22.7 20.3 16.7 27.9 21.4  8.1 37.6\n 15.6 29.6 22.9 24.8 24.4 50.  28.7 50.  16.5 18.2 50.  16.2 14.1 21.2\n 18.4 25.  50.  21.2 20.4 15.2 22.  19.8 22.1 23.9 24.6 23.9 21.7 44.8\n  7.2 18.5 20.1 23.3 19.2 29.1 31.  22.9 27.5 39.8 22.  22.8 22.9 14.3\n 14.5 22.4 19.3 32.  20.1 18.3 24.5 18.4 23.1 22.6 20.2 17.8 31.6 43.5\n 36.4 11.3 20.5 23.2 29.8 20.6 24.3 18.1 19.1 21.4 31.5 19.2 14.3 24.8\n 21.1 18.2 48.3 19.4 21.2 10.9 27.5 34.7 14.4 22.8 17.8 50.  24.4 12.8\n 30.8 28.2 25.  33.1 27.5 12.7 43.1 13.4 21.5 33.4 23.8 21.  26.6 18.5\n 23.  24.1 20.5 32.2 14.4 11.8 19.5 23.7 13.2 29.  18.2 18.6 23.  42.3\n 17.2 16.2 20.  30.3 20.9 20.4 24.8 18.7 16.8 22.5 18.8 23.7 23.8 19.6\n 20.4 16.1 44.  19.3 17.4 10.2 11.7 37.2 11.  23.6 22.8 15.  34.9 17.9\n 24.4 24.5  6.3 29.4 10.4 38.7 20.  19.4 37.  50.  18.7 48.5 35.4 23.4\n  7.  50.  20.7 35.4  9.6 25.1 16.1 27.  16.6 13.3 25.  24.  19.6 29.6\n 21.7 19.1 22.  13.3 27.1 22.9 33.2 13.5 14.5  8.3 41.7 31.2 23.9 23.1\n 24.3 18.3 20.8 28.  19.5 21.5 13.1 12.5 31.7 13.1 23.1 14.5 22.2 13.1\n 37.3 22.  10.2  5.  19.3 16.  18.6 50.  31.6 24.1 15.6 19.4 23.3 23.2\n 13.6].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#分别初始化对特征和目标值的标准化器\n",
    "ss_X = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "\n",
    "#分别对训练和测试数据的特征及目标值进行标准化处理\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "X_test = ss_X.transform(X_test)\n",
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)\n",
    "y_train = ss_y.fit_transform(y_train)\n",
    "y_test = ss_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fir(X_train,y_train)\n",
    "lr_y_predict = lr.predict(X_test)\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgdr = SGDRegressor()\n",
    "sgdr.fit(X_train,y_train)\n",
    "sgdr_y_predict = sgdr.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
